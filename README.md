# Awesome-LLM-for-Chart [![Awesome](https://awesome.re/badge.svg)](https://awesome.re)

A curated list of papers and resources on using **Large Language Models (LLMs) for Chart Understanding**, including chart data extraction, visual reasoning, chart-based QA, and chart-to-knowledge generation.

Large Language Models (LLMs) have demonstrated impressive capabilities in natural language processing, vision, and multimodal tasks. Among these, understanding and reasoning over **Data Visualizations**â€”such as charts, plots, and graphsâ€”is emerging as a critical research direction.
This repository aims to bridge the gap between **Chart Understanding** and **Large Language Models** by collecting high-quality research papers and resources that explore how LLMs can be applied to **extract**, **interpret**, and **reason** about visual data representations in charts.

## ğŸ—‚ï¸ Table of Contents

- ğŸ“Œ [Awesome-LLM-for-Chart](#awesome-llm-for-chart)
  - ğŸ—‚ï¸ [Table of Contents](#table-of-contents)
  - ğŸ“Š [Chart Understanding](#chart-understanding)
  - ğŸ§¾ [Chart Data Extraction and Structuring](#chart-data-extraction-and-structuring)
  - â“ [Visual Question Answering over Charts (ChartQA)](#visual-question-answering-over-charts-chartqa)
  - ğŸ“ [Chart Captioning (Summarization)](#chart-captioning-summarization)
  - ğŸ“š [Benchmarks & Surveys](#benchmarks--surveys)
  - ğŸ¤ [Contributing](#contributing)




## ğŸ“Š Chart Understanding
*Coming soon...*

## ğŸ§¾ Chart Data Extraction and Structuring
- **ChartKG: A Knowledge-Graph-Based Representation for Chart Images** <img src='https://img.shields.io/badge/TVCG-2024-yellow'> <a href='https://ieeexplore.ieee.org/document/10711251/'><img src='https://img.shields.io/badge/Paper-purple'></a>


## â“ Visual Question Answering over Charts (ChartQA)
- *Ahmed Masry, Xuan Long Do, Jia Qing Tan, Shafiq Joty, Enamul Hoque.* **ChartQA: A Benchmark for Question Answering about Charts with Visual and Logical Reasoning** <img src='https://img.shields.io/badge/ACL_Findings-2022-yellow'> <a href='https://aclanthology.org/2022.findings-acl.177/'><img src='https://img.shields.io/badge/Paper-purple'></a><a href='https://github.com/vis-nlp/ChartQA'><img src='https://img.shields.io/badge/Dataset-red'></a> <img src='https://img.shields.io/badge/Benchmark-green'>

- **Answering Questions about Charts and Generating Visual Explanations** <img src='https://img.shields.io/badge/CHI-2020-yellow'> <a href='https://dl.acm.org/doi/10.1145/3313831.3376467/'><img src='https://img.shields.io/badge/Paper-purple'></a>

- *Nitesh Methani, Pritha Ganguly, Mitesh M. Khapra, Pratyush Kumar.* **PlotQA: Reasoning over Scientific Plots**
  <img src='https://img.shields.io/badge/WACV-2020-yellow'> <a href='https://arxiv.org/abs/1909.00997'><img src='https://img.shields.io/badge/PDF-purple'></a><a href='https://github.com/NiteshMethani/PlotQA'><img src='https://img.shields.io/badge/Dataset-red'></a>



## ğŸ“ Chart Captioning (Summarization)
*Coming soon...*


## ğŸ“š Benchmarks & Surveys
*Coming soon...*

## ğŸ¤ Contributing
ğŸ‘ Contributions to this repository are welcome! 

If you have come across relevant resources, feel free to open an issue or submit a pull request.
ğŸ“Œ ç¤ºä¾‹æ ¼å¼ï¼š
```
- *Author1, Author2, Author3, ...*  **Paper Title (bolded)** <img src='https://img.shields.io/badge/Conference_Journal_Name-Year-Color'><a href='PDF_Link'><img src='https://img.shields.io/badge/Paper-purple'></a><a href='Code_Link'><img src='https://img.shields.io/badge/Code-orange'></a><a href='Dataset_Link'><img src='https://img.shields.io/badge/Dataset-red'></a><img src='https://img.shields.io/badge/Benchmark-green'>

```

[#contributing]: #-contributing
[#benchmarks--surveys]: #-benchmarks--surveys
